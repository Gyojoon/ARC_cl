mode: 'concept_our_loss'
entity: 'whatchang'
permute_mode: False
train_batch_size: 128
valid_batch_size: 16
lr: 1e-3
batch_size: train_batch_size
epochs: 1000
seed: 777
model_name: 'vae'
temperature: 1
use_wandb: False
use_scheduler: False
scheduler_name: 'LROn'
patience: 20
loss_mode: 'nx_xent_loss'
dataset_mode: 'concept'
pre_trained: result\CL_our_loss_0.3139604926109314.pt # result/CL_nx_xent_loss_0.1956702619791031.pt  result/CL_our_loss_0.4163462817668915.pt